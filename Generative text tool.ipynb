{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571,
     "referenced_widgets": [
      "3407a7408bcd45d6b36cf51a676fc263",
      "4f0b617d653d47e4948e2cd9b51a0e24",
      "57c13d8f0a8e4fb7ac037a9741f176c3",
      "f4d49045ca324c98b05a1469cb8f33b5",
      "157d5dc37245417b84bba840addccce6",
      "cf894ee162f94e58844ae729ebe6db47",
      "d7574101a73043a1877f3d9941dee060",
      "416a0d94a9994696a1c22e88d99b5fde",
      "53edb3bb5f364f7387b777f4c371b913",
      "a8c1088efa0f4800b764bba61e93041d",
      "e973d7c16a3b46929bf2e041af86f57c",
      "8f785d1a4d7444e6aec796c90a60d4ad",
      "d0d202d2bcbc4f1eb1613de6813cc547",
      "ee22219bf9b14398aab9e32e50e2fd5a",
      "0f7f00699f77455b993b9197adea7829",
      "b31f49c6615e42f5b7f7e19f144c2159",
      "136b068939034c38a81d8ebb0ffd9e84",
      "403d312b41be45519b8f7533fb117486",
      "51285b81e2ad4c068407be7acc0f79ef",
      "1988408034ae4c6fb9080573bb11780f",
      "27c5ccb6b4ec45c6b08566c12b43431f",
      "068c2821352b44cd999bb8a2be600a5c",
      "2d979b102e4b4526afa94e711bc41616",
      "17a1105f744c43fb99f72c5f41254455",
      "3f834464c66f4fc2b87a45ec5ff02e3f",
      "2176c4355ac741658ba11d357b07dc0d",
      "f70c809ce8164bb98f45540f54bbd0c2",
      "aca08683bad24aca81212245d8504450",
      "4935f10b00dd48d78984bcd1af73b99d",
      "d5fef197ab024c69bbe00deda8f5c66e",
      "ddbf061c2ccf4d02bb38a6c801be1005",
      "55aa0741506f488aade7d012bbb22068",
      "54d90c26cd334781a7e2442189fb6b00",
      "f4e9fc7a18e14b7ba061e264f79450c3",
      "d3f2660275564773ab5c74d2e53dc4af",
      "909c276dfd9c438fbdd715d927adb6f5",
      "7342ea22bc6b46809f21c48ed14a5199",
      "d2a21a62e64d407f97ee2a076581e259",
      "6c032053a7544da5802bcccbfba40bb0",
      "f9fe5aecf164439c81a5c291c91ba527",
      "9a020d6c216c49cab399b7eac04f5117",
      "b2f5fe55fdf3416f897ccbf3ca2bc343",
      "0239b24569534e1ab972a6de98220b60",
      "c35357faa3424ca4b6c7f375c555d348",
      "e7d0dc45ca744bb0996597c714ab2e56",
      "3a8256fc4fae48129e8f4fbd0e2f24bf",
      "0ba772a03b2c4698a112efdce510baf3",
      "746d30e704204588bd754d2603274fdc",
      "c6f894e1aaac45fab51ba8c8f34aa0fc",
      "c6e7a08f2ec749f3862ba2e5439e9907",
      "3d2c05dbf7e64248805f1ead74fb1431",
      "25ccefa041ac4775a331b241c3c83b04",
      "52e90ae5c02947abbb31e61cf0ae8432",
      "b05b8ae9b8ef4fc5bd7de9ce2edbf333",
      "bd26ec1e77fe432db414560aeb9c78a9",
      "8184f14931aa4346a43316117f71642f",
      "b9c520981c2c4f1eb8bee57abcb0f62c",
      "e660968cdcd2480bb3d32a4f3b4c1513",
      "1a6f5fa2347044eca6111b6d5fbc59f2",
      "d17d11028c3d4e6bb69ab9ac6f1c0f06",
      "a7b259b334d2442d9556d69db5efaca7",
      "4d0c2e6ec12c449eb2cb0c31dc9b9d1a",
      "a096ca371fd94c73b432f2f31a3ca40d",
      "3385e353898a43d0ae4faab50cd5ede5",
      "5a13820e88284189b38ee8e6905f7587",
      "8115f48cabdf45e28daef689b65c1bc0",
      "9cdbb85d89804849b63c5ea54c7f3ffd",
      "48d43dc412544b20bf2ef1b9a2576e19",
      "1fa96b082bec4afaa0b8137fe72ab28b",
      "2ca2409ab78e4201b6d1bd4f37e0d93e",
      "92854f11953a4acca11a47f0f2c21cb2",
      "ee88114a4160425e9fd04e189c22b19e",
      "487819cf6805479c8fff58fc596b445a",
      "e5be9ef1cf4a405184943052dabe7525",
      "1b5901a7ea4246baafcfb62a8bba6d37",
      "29b592a17ef54c5d99405c856fe3f135",
      "1e1fb5ddc2684afeb5600571ff5088f9",
      "612d450ded56470ba5e8eca681f62c31",
      "21c69cf9d7b44c2ea447a2050f51455c",
      "18e140a4e1d24c058c4abbef53b05b59",
      "20b96ca47db14c7299836c9fcab8f31a",
      "54585760f91c409e92a58fdcdcee71cc",
      "e8ef6dfd9a254ccea236af0f96270cd5",
      "6d88d482565341efaf780073ff1aea44",
      "050d3086d124485db022b15910cd1df8",
      "127aaa8aab8d4e59a3c490905d27375f",
      "15c18f296a2346d6a4520d754bd5b4be",
      "030489f763554409936edd080d3a89be"
     ]
    },
    "id": "EKXRjyJK6oWN",
    "outputId": "1bb3d171-c971-4248-fc74-0fa10215f580"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3407a7408bcd45d6b36cf51a676fc263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f785d1a4d7444e6aec796c90a60d4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d979b102e4b4526afa94e711bc41616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e9fc7a18e14b7ba061e264f79450c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d0dc45ca744bb0996597c714ab2e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8184f14931aa4346a43316117f71642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdbb85d89804849b63c5ea54c7f3ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612d450ded56470ba5e8eca681f62c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a topic: artificial intelligance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Paragraph:\n",
      "\n",
      "Write a paragraph about artificial intelligance:\n",
      "\n",
      "The term artificial intelligance is used to describe the way in which a person's voice is used to communicate with others. The term artificial intelligance is used to describe the way in which a person's voice is used to communicate with others. The term artificial intelligance is used to describe the way in which a person's voice is used to communicate with others. The term artificial intelligance is used to describe the way in which a person's voice is used to communicate with others. The term artificial intelligance is used to describe the way in which a person's voice is used to communicate with others. The term artificial intelligance is used to describe the way in which a person's voice is used to\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Load GPT-Neo model and tokenizer via Hugging Face pipeline\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-125M')\n",
    "\n",
    "# Optional: set a seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Function to generate text based on a user-provided topic\n",
    "def generate_paragraph(topic, max_length=150):\n",
    "    prompt = f\"Write a paragraph about {topic}:\"\n",
    "    result = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Get user input\n",
    "user_topic = input(\"Enter a topic: \")\n",
    "paragraph = generate_paragraph(user_topic)\n",
    "print(\"\\nGenerated Paragraph:\\n\")\n",
    "print(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hw65drUn6pXU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
